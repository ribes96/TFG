{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación con DecisionTree con el dataset Digits de scikit-learn normalizando los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casi 1800 imágenes de 8x8 con los dígitos 0..9. Cada píxel se representa con un número entre 0..15, que representa un color en la escala de grises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se hará el training con los datos normalizados, igual que hacen en algunos ejemplo de scikit-learn (dividen cada fila por 16 y luego le restan la media). En este notebook el training se hará directamente con los datos normalizados, sin usar ningún tipo de sampler. Para ver el mismo código pero usando RBFSampler, estará en otro notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = digits.data\n",
    "target = digits.target\n",
    "N = data.shape[0]\n",
    "prop_train = 2 / 3\n",
    "N_train = math.ceil(N * prop_train)\n",
    "N_test = N - N_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaliza los datos entre 0 y 1 y luego los centra en la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data /= 16\n",
    "data -= data.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los primeros 2/3 de los datos son de train, y el resto son de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[:N_train]\n",
    "data_test = data[N_train:]\n",
    "\n",
    "target_train = target[:N_train]\n",
    "target_test = target[N_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer n_runs ejecuciones y devolver la media de puntuación de todas ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 50\n",
    "train_scores = []\n",
    "test_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_runs):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(data_train, target_train)\n",
    "    train_score = clf.score(data_train, target_train)\n",
    "    test_score = clf.score(data_test, target_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of test scores: 0.77889816360601\n",
      "Mean of train scores: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of test scores:\",np.mean(test_scores))\n",
    "print(\"Mean of train scores:\", np.mean(train_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of test scores: 0.008533220410195561\n",
      "Standard deviation of train scores: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard deviation of test scores:\",np.std(test_scores))\n",
    "print(\"Standard deviation of train scores:\",np.std(train_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El árbol es capaz de ajustar muy bien. También es capaz de aprender, pero no generaliza demasiado, sobreajusta. De todos modos, es mejor que tirar una moneda. No parece haber ninguna mejoría entre normalizar los datos y no hacerlo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
