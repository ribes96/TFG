{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación con SVM Lineal con el dataset Digits de scikit-learn normalizando los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casi 1800 imágenes de 8x8 con los dígitos 0..9. Cada píxel se representa con un número entre 0..15, que representa un color en la escala de grises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se hará el training con los datos normalizados, igual que hacen en algunos ejemplo de scikit-learn (dividen cada fila por 16 y luego le restan la media). En este notebook el training se hará directamente con los datos normalizados, sin usar ningún tipo de sampler. Para ver el mismo código pero usando RBFSampler, estará en otro notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = digits.data\n",
    "target = digits.target\n",
    "N = data.shape[0]\n",
    "prop_train = 2 / 3\n",
    "N_train = math.ceil(N * prop_train)\n",
    "N_test = N - N_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaliza los datos entre 0 y 1 y luego los centra en la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data /= 16\n",
    "data -= data.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los primeros 2/3 de los datos son de train, y el resto son de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[:N_train]\n",
    "data_test = data[N_train:]\n",
    "\n",
    "target_train = target[:N_train]\n",
    "target_test = target[N_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer n_runs ejecuciones y devolver la media de puntuación de todas ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 50\n",
    "train_scores = []\n",
    "test_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_runs):\n",
    "    #clf = DecisionTreeClassifier()\n",
    "    clf = LinearSVC()\n",
    "    \n",
    "    # Samplear los datos\n",
    "    indices = np.arange(len(data))\n",
    "    indices = np.random.choice(indices, len(indices), replace = False) # Mezclar los indices\n",
    "    train_indices = indices[:N_train] # Los N_train primeros son de train\n",
    "    test_indices = indices[N_train:] # El resto son de test\n",
    "    dat_train = np.take(data, train_indices, axis = 0)\n",
    "    targ_train = np.take(target, train_indices, axis = 0)\n",
    "\n",
    "    dat_test = np.take(data, test_indices, axis = 0)\n",
    "    targ_test = np.take(target, test_indices, axis = 0)\n",
    "    \n",
    "    clf.fit(dat_train, targ_train)\n",
    "    train_score = clf.score(dat_train, targ_train)\n",
    "    test_score = clf.score(dat_test, targ_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of test scores: 0.9611018363939902\n",
      "Mean of train scores: 0.9918530884808014\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of test scores:\",np.mean(test_scores))\n",
    "print(\"Mean of train scores:\", np.mean(train_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of test scores: 0.00752734578804375\n",
      "Standard deviation of train scores: 0.0019293516144498976\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard deviation of test scores:\",np.std(test_scores))\n",
    "print(\"Standard deviation of train scores:\",np.std(train_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo es capaz de ajustar y generalizar correctamente. No parece que haya ninguna diferencia entre normalizar los datos y no hacerlo. Los resultados son bastante parecidos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
